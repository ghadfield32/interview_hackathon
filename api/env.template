# Local development environment template
# Copy this to .env and modify as needed

# Database
DATABASE_URL=sqlite+aiosqlite:///./app.db

# Security (generate a secure key for production)
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# CORS
ALLOWED_ORIGINS=*

# Redis Configuration (for rate limiting)
REDIS_URL=redis://localhost:6379

# Rate Limiting Configuration
RATE_LIMIT_DEFAULT=60
RATE_LIMIT_CANCER=30
RATE_LIMIT_LOGIN=3
RATE_LIMIT_TRAINING=2
RATE_LIMIT_WINDOW=60
# 5 minutes for light endpoint (iris/predict)
RATE_LIMIT_WINDOW_LIGHT=300   
RATE_LIMIT_LOGIN_WINDOW=20

# MLflow Configuration
# For Railway: Create a Volume named "mlruns" and mount at /data/mlruns
# Then set these to use the persistent volume:
# MLFLOW_TRACKING_URI=file:/data/mlruns
# MLFLOW_REGISTRY_URI=file:/data/mlruns
# 
# For local development, use local file store:
MLFLOW_TRACKING_URI=file:./mlruns_local
MLFLOW_REGISTRY_URI=file:./mlruns_local

# Model Training Flags
SKIP_BACKGROUND_TRAINING=0
AUTO_TRAIN_MISSING=1
UNIT_TESTING=0

# Debug Flags (keep OFF in production)
DEBUG_RATELIMIT=0 

# JAX/XLA Configuration
# Host has a single logical CPU device â€“ prevents JAX allocating all cores
XLA_FLAGS=--xla_force_host_platform_device_count=1

# Force CPU backend for JAX (uncomment if GPU issues occur)
# JAX_PLATFORM_NAME=cpu

# PyTensor configuration (CPU only to avoid C++ compilation)
PYTENSOR_FLAGS=device=cpu,floatX=float32 

RETAIN_RUNS_PER_MODEL=5
MLFLOW_GC_AFTER_TRAIN=1
