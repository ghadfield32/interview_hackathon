# .devcontainer/docker-compose.yml - TensorFlow removed, optimized for faster builds
name: ${ENV_NAME:-cancer_bayes_iris_env}

services:
  datascience:
    build:
      context: ..
      dockerfile: .devcontainer/Dockerfile
      args:
        CUDA_TAG: ${CUDA_TAG:-12.8.0}
        PYTHON_VER: ${PYTHON_VER:-3.10}
        ENV_NAME: ${ENV_NAME:-cancer_bayes_iris_env}
      # Enable BuildKit for better caching
      target: ""
      cache_from:
        - nvidia/cuda:${CUDA_TAG:-12.8.0}-runtime-ubuntu22.04

    restart: unless-stopped
    depends_on:
      mlflow:
        condition: service_healthy

    # GPU configuration - simplified
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    init: true
    gpus: all
    shm_size: 4g  # Reduced from 8g since no TensorFlow
    ulimits:
      memlock: -1
      stack: 67108864

    environment:
      # Core configuration
      - PYTHON_VER=${PYTHON_VER:-3.10}
      - UV_PROJECT_ENVIRONMENT=/app/.venv

      # GPU Environment  
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - LD_LIBRARY_PATH=/app/.venv/lib:/usr/local/cuda/lib64

      # Simplified memory management (jemalloc)
      - LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2
      - MALLOC_ARENA_MAX=1
      - MALLOC_TCACHE_MAX=0
      - PYTORCH_NO_CUDA_MEMORY_CACHING=1

      # JAX Configuration (RTX 5080 optimized)
      - XLA_PYTHON_CLIENT_PREALLOCATE=false
      - XLA_PYTHON_CLIENT_ALLOCATOR=platform
      - XLA_PYTHON_CLIENT_MEM_FRACTION=0.25
      - XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda
      - JAX_PREALLOCATION_SIZE_LIMIT_BYTES=8589934592

      # PyTorch Configuration (RTX 5080 optimized)
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:True

      # Jupyter
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-jupyter}

    volumes:
      - ..:/workspace:delegated
      - ../mlruns:/workspace/mlruns
      # Cache mounts for faster rebuilds
      - uv-cache:/root/.cache/uv

    ports:
      - "${HOST_JUPYTER_PORT:-8890}:8888"
      - "${HOST_TENSORBOARD_PORT:-6008}:6008"
      - "${HOST_EXPLAINER_PORT:-8050}:8050"
      - "${HOST_STREAMLIT_PORT:-8501}:8501"

    command: >
      bash -lc '
        echo "[boot] Activating environment...";
        source /app/.venv/bin/activate;
        echo "[boot] Starting Jupyter Lab...";
        jupyter lab --ip=0.0.0.0 --port=8888 --allow-root 
        --NotebookApp.token="${JUPYTER_TOKEN}" 
        --NotebookApp.allow_origin="*" 
        --NotebookApp.open_browser=false
      '

    healthcheck:
      test: ["CMD-SHELL", "python -c 'import jupyterlab' 2>/dev/null || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s  # Reduced from 60s

    labels:
      - "com.docker.compose.project=${ENV_NAME:-cancer_bayes_iris_env}"
      - "com.docker.compose.service=datascience"
      - "description=AI/ML Dev Env (PyTorch+JAX GPU)"

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlflow_artifacts
    environment:
      MLFLOW_EXPERIMENTS_DEFAULT_ARTIFACT_LOCATION: /mlflow_artifacts
    volumes:
      - ../mlruns:/mlflow_artifacts
      - ../mlflow_db:/mlflow_db
    ports:
      - "${HOST_MLFLOW_PORT:-5000}:5000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5000/health').raise_for_status()"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 15s  # Reduced from 30s

# Named volume for uv cache persistence
volumes:
  uv-cache:
